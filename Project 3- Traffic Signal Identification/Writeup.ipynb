{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective :\n",
    "\n",
    "In this assignment we have to build a classifier to identify the type of traffic signals(Germany) on road which will help self driving car to take appropriate measures for further driving.\n",
    "\n",
    "##### We are going to follow following steps :\n",
    "1. Data Import \n",
    "2. Data Exploration\n",
    "3. Data preprocessing\n",
    "4. Model Training and Validation\n",
    "5. Testing on 5 other images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import\n",
    "\n",
    "Data is present in pickel format which is good for storing large files in compact format. Each file for train , test and validation contains following :\n",
    "1. Labels - Label of image\n",
    "2. Features -  Image matrix (32X32)\n",
    "3. Size - Original size of the image\n",
    "4. Coords - Image coordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration\n",
    "\n",
    "1. Basic summary of data such as size of train , validation and test data set \n",
    "2. Number of classes to predict\n",
    "3. see how the image look like\n",
    "4. Distribution of labels in training, validation and test data set so as to check the distibution of particular variables in all three data set is approx same or not. As it is going to affect the prediction results\n",
    "5. It is observed that data is imbalance and most occuring labels are 20,30,60,70 speed signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have executed the LeNet Model as taught in class without preprocessing images , but accuracy was approx 83% on validation dataset . Then went for preprocessing to imporve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing\n",
    "\n",
    "Following experiments are tried :\n",
    "1. Data Augmentation using Keras preprocessing module by rotating and shifting the image . But there was only 2% increament in accuracy that is from 83% to 85%. \n",
    "2. Data Augmentation by changing the brightness by random number after converting it to YUV color space . It is done because when you look at the images in training data sets , most of them shadows and brightness variations\n",
    "3. Data Augmentation by adding blur in images as while testing the default model result without pre processing, it is noticed that blurred images are getting classified correctly .\n",
    "4. Normalizing the data by 128 as mentioned in notes of notebook.This is done to bring all images in same scale and it will help in fast conversion of neural net as happens in gradient descent\n",
    "5. Gray scale conversion of images also didn't help in increasing the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training and Validation\n",
    "\n",
    "Firstly we need to make changes in shapes being recievied by the LeNet from teaching module as now image has 3 dimension and number of classes in output layer to be 43 not 10.\n",
    "\n",
    "Following changes are made :\n",
    "1. Addition of drop out layer : Without drop out layer , there was diff in accuracy of traiing and test data set , may be because of overfitting and after adding drop out model is getting trained faster \n",
    "2. Increase in number of epochs because with less number of epochs accuracy was not stable and also keeps on increasing.\n",
    "3. Decreasing the learning rate to get the more optimal weights\n",
    "4. Increasing the batch size for better training as model is going to see more images in each iteration\n",
    "\n",
    "After training the model , got the accuracy of approx 94% on validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing on web images \n",
    "Model is working good , out of 5 images 4 are correctly predicted . One with 60 speed limit was getting predicted as Yield may be because the 60 forms triangular shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
